{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import gzip\n",
    "#sckit learn\n",
    "\n",
    "from sklearn.preprocessing  import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from data_processor import DataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"background-color: lightyellow;\">Data retrieval task</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_config(file_name):\n",
    "\n",
    "    with open(file_name, 'r', encoding=\"UTF-8\") as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    return config\n",
    "\n",
    "\n",
    "def parse_metadata(file_path):\n",
    "    data = {}\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        splited = line.split('\\t', 1)\n",
    "        if len(splited) >= 2:\n",
    "            # Only include lines where the first part is '!Sample_title' or does not start with '!'\n",
    "            if splited[0].strip() == '!Sample_title' or not splited[0].lstrip().startswith('!'):\n",
    "                data[splited[0].strip()] = splited[1].strip().strip(\n",
    "                    '\"').split(\"\\t\")\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index').transpose()\n",
    "    df.drop(columns=['!Sample_title'], inplace=True)\n",
    "    df.drop('\"ID_REF\"', inplace=True, axis=1)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "\n",
    "    config = get_config('config.yaml')\n",
    "    lung3 = config['lung3_csv']\n",
    "    gene = config['gene']\n",
    "\n",
    "    lung3_df = pd.read_csv(lung3)\n",
    "    gene_expression_df = parse_metadata(gene)\n",
    "\n",
    "    combined_df = lung3_df.merge(gene_expression_df, left_index=True,right_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def sub_classification(histology):\n",
    "    if \"Carcinoma\" in histology:\n",
    "        return 'Carcinoma'\n",
    "    elif \"Adenocarcinoma\" in histology:\n",
    "        return 'Adenocarcinoma'\n",
    "    else:\n",
    "        return 'Others'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"background-color: lightyellow;\">Feature engineering Task</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureProcessing(TransformerMixin, BaseEstimator): \n",
    "    def __init__(self, covariance_threshold=0, quantile_percentage=95, nan_threshold =35):\n",
    "        self.covariance_threshold = covariance_threshold\n",
    "        self.quantile_percentage = quantile_percentage\n",
    "        self.nan_threshold= nan_threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        data_processor = DataProcessor(X)\n",
    "        data_processor.remove_nonrelated_columns()\n",
    "        data_processor.impute_notavailable_values('characteristics.tag.grade')\n",
    "        data_processor.drop_nan_columns(self.nan_threshold)\n",
    "        # data_processor.change_column_datatype()\n",
    "        \n",
    "        data_processor.cramerV(y, self.covariance_threshold)\n",
    "        self.covarrianced_columns = data_processor.covarrianced_columns\n",
    "        removed_catagorical_features = set(data_processor.find_cols_on_type('object')) - set(self.covarrianced_columns)\n",
    "        data_processor.drop_columns(column_list = list(removed_catagorical_features))\n",
    "        data_processor.selecting_high_variance_gene_expression(self.quantile_percentage)\n",
    "        self.features = data_processor.dataframe.columns\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(data_processor.dataframe[data_processor.find_cols_on_type('float64')])\n",
    "        \n",
    "        self.one_hot_encoder= OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.one_hot_encoder.fit(data_processor.dataframe[data_processor.covarrianced_columns])\n",
    "        self.processed_df = data_processor.dataframe\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "    \n",
    "       data_processor = DataProcessor(X)\n",
    "       data_processor.dataframe = data_processor.dataframe[self.features]\n",
    "       data_processor.fit_standard_scaling(self.scaler)\n",
    "       data_processor.encoding_catagorical_features(self.one_hot_encoder, self.covarrianced_columns)\n",
    "       data_processor.dataframe.fillna(0, inplace=True)\n",
    "       \n",
    "       X = data_processor.dataframe\n",
    "\n",
    "       return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"background-color: lightyellow;\">Pipeline Task</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from codecarbon import track_emissions\n",
    "\n",
    "def return_train_test_split():\n",
    "    encoder = LabelEncoder()\n",
    "    X = retrieve_data()\n",
    "    y = X['characteristics.tag.histology'].apply(lambda x: sub_classification(x))\n",
    "    y_encoded = pd.DataFrame(encoder.fit_transform(y),columns=['classes']).classes\n",
    "    X.drop(columns='characteristics.tag.histology',inplace=True)\n",
    "\n",
    "    # Before doing any preprocessing steps we will split the data into train and test inorder to prevent data leakage\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y_encoded, random_state=42)\n",
    "\n",
    "\n",
    "    test_y.reset_index(drop=True, inplace = True)\n",
    "    train_y.reset_index(drop=True, inplace = True)\n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:34:00] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:34:00] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:34:00] No GPU found.\n",
      "[codecarbon INFO @ 21:34:00] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:34:00] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 21:34:01] We saw that you have a Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 21:34:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 21:34:01] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:34:01]   Platform system: Linux-6.1.0-32-amd64-x86_64-with-glibc2.36\n",
      "[codecarbon INFO @ 21:34:01]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 21:34:01]   CodeCarbon version: 2.2.2\n",
      "[codecarbon INFO @ 21:34:01]   Available RAM : 880.353 GB\n",
      "[codecarbon INFO @ 21:34:01]   CPU count: 80\n",
      "[codecarbon INFO @ 21:34:01]   CPU model: Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 21:34:01]   GPU count: None\n",
      "[codecarbon INFO @ 21:34:01]   GPU model: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Feature processing ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:34:19] Energy consumed for RAM : 0.001390 kWh. RAM Power : 330.1325168609619 W\n",
      "[codecarbon INFO @ 21:34:19] Energy consumed for all CPUs : 0.000179 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:34:19] 0.001569 kWh of electricity used since the beginning.\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor.py:116: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cramer.fillna(value=0, inplace=True)\n",
      "[codecarbon INFO @ 21:34:22] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 21:34:22] Energy consumed for RAM : 0.001478 kWh. RAM Power : 330.1325168609619 W\n",
      "[codecarbon INFO @ 21:34:22] Energy consumed for all CPUs : 0.000190 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:34:22] 0.001668 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:34:22] Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def run_feature_processing():\n",
    "    train_X, test_X, train_y, test_y = return_train_test_split()\n",
    "    print(\"###### Feature processing ######\")\n",
    "    fp = FeatureProcessing()\n",
    "    fp.fit(train_X,train_y)\n",
    "    x = fp.transform(train_X)\n",
    "    \n",
    "run_feature_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b206076adfde74b94edf3e7fcee64be8304c1723f9b5959762d795d94eb4b82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
