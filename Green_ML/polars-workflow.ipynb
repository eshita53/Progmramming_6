{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import yaml\n",
    "import gzip\n",
    "#sckit learn\n",
    "\n",
    "from sklearn.preprocessing  import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from data_processor_polars import DataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: lightyellow;\">Data retrieval task</span>\n",
    "- Retrieve the data. (No cleaning needed yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_config(file_name):\n",
    "\n",
    "    with open(file_name, 'r', encoding=\"UTF-8\") as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    return config\n",
    "\n",
    "\n",
    "def parse_metadata(file_path):\n",
    "    data = {}\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        splited = line.split('\\t', 1)\n",
    "        if len(splited) >= 2:\n",
    "            # Only include lines where the first part is '!Sample_title' or does not start with '!'\n",
    "            if splited[0].strip() == '!Sample_title' or not splited[0].lstrip().startswith('!'):\n",
    "                data[splited[0].strip()] = splited[1].strip().strip(\n",
    "                    '\"').split(\"\\t\")\n",
    "\n",
    "    df = pl.LazyFrame(data)\n",
    "    df = df.drop(['!Sample_title'])\n",
    "    df = df.drop('\"ID_REF\"',)\n",
    "    # df = df.apply(pl.to_numeric, errors='coerce')\n",
    "    df = df.with_columns(\n",
    "    pl.all().cast(pl.Float64, strict=False)  # Convert all **non-string** columns\n",
    ")   \n",
    "    return df.collect()\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "\n",
    "    config = get_config('config.yaml')\n",
    "    lung3 = config['lung3_csv']\n",
    "    gene = config['gene']\n",
    "\n",
    "    lung3_df = pl.read_csv(lung3)\n",
    "    \n",
    "\n",
    "    gene_expression_df = parse_metadata(gene)\n",
    "    \n",
    "    combined_df = gene_expression_df.with_columns([lung3_df[col] for col in lung3_df.columns])\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def sub_classification(histology):\n",
    "    if \"Carcinoma\" in histology:\n",
    "        return 'Carcinoma'\n",
    "    elif \"Adenocarcinoma\" in histology:\n",
    "        return 'Adenocarcinoma'\n",
    "    else:\n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: lightyellow;\">Feature engineering Task</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProcessing(TransformerMixin, BaseEstimator): \n",
    "    def __init__(self, covariance_threshold=0, quantile_percentage=95, nan_threshold =35):\n",
    "        self.covariance_threshold = covariance_threshold\n",
    "        self.quantile_percentage = quantile_percentage\n",
    "        self.nan_threshold= nan_threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        data_processor = DataProcessor(X)\n",
    "        data_processor.remove_nonrelated_columns()\n",
    "        data_processor.impute_notavailable_values('characteristics.tag.grade')\n",
    "        data_processor.drop_nan_columns(self.nan_threshold)\n",
    "        # data_processor.change_column_datatype()\n",
    "        \n",
    "        data_processor.cramerV(y, self.covariance_threshold)\n",
    "        self.covarrianced_columns = data_processor.covarrianced_columns\n",
    "        removed_catagorical_features = set(data_processor.find_cols_on_type(pl.String)) - set(self.covarrianced_columns)\n",
    "        data_processor.drop_columns(column_list = list(removed_catagorical_features))\n",
    "        data_processor.selecting_high_variance_gene_expression(self.quantile_percentage)\n",
    "        self.features = data_processor.dataframe.columns\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(data_processor.dataframe[data_processor.find_cols_on_type(pl.Float64)])\n",
    "        \n",
    "        self.one_hot_encoder= OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.one_hot_encoder.fit(data_processor.dataframe[data_processor.covarrianced_columns])\n",
    "        self.processed_df = data_processor.dataframe\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "    \n",
    "       data_processor = DataProcessor(X)\n",
    "       data_processor.dataframe = data_processor.dataframe[self.features]\n",
    "       data_processor.fit_standard_scaling(self.scaler)\n",
    "       data_processor.encoding_catagorical_features(self.one_hot_encoder, self.covarrianced_columns)\n",
    "       data_processor.dataframe = data_processor.dataframe.fill_null(value=0)\n",
    "       \n",
    "       X = data_processor.dataframe\n",
    "\n",
    "       return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"background-color: lightyellow;\">Pipeline Task</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from codecarbon import track_emissions\n",
    "def return_train_test_split():\n",
    "    encoder = LabelEncoder()\n",
    "    dataset = retrieve_data()\n",
    "    y = dataset[\"characteristics.tag.histology\"].map_elements(lambda x: sub_classification(x), return_dtype=pl.String)\n",
    "    y_encoded = pl.DataFrame(encoder.fit_transform(y)).to_series()\n",
    "    X = dataset.drop('characteristics.tag.histology')\n",
    "    # Before doing any preprocessing steps we will split the data into train and test inorder to prevent data leakage\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y_encoded, random_state=42)\n",
    "    return train_X, test_X, train_y, test_y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:34:47] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:34:47] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:34:47] No GPU found.\n",
      "[codecarbon INFO @ 21:34:47] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:34:47] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 21:34:48] We saw that you have a Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 21:34:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 21:34:48] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:34:48]   Platform system: Linux-6.1.0-32-amd64-x86_64-with-glibc2.36\n",
      "[codecarbon INFO @ 21:34:48]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 21:34:48]   CodeCarbon version: 2.2.2\n",
      "[codecarbon INFO @ 21:34:48]   Available RAM : 880.353 GB\n",
      "[codecarbon INFO @ 21:34:48]   CPU count: 80\n",
      "[codecarbon INFO @ 21:34:48]   CPU model: Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 21:34:48]   GPU count: None\n",
      "[codecarbon INFO @ 21:34:48]   GPU model: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Feature processing ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/Documents/Programming_6/Green_ML/data_processor_polars.py:158: RuntimeWarning: Unable to calculate Cramer's V using bias correction. Consider not using bias correction\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 21:35:00] \n",
      "Graceful stopping: collecting and writing information.\n",
      "Please wait a few seconds...\n",
      "[codecarbon INFO @ 21:35:00] Energy consumed for RAM : 0.000816 kWh. RAM Power : 330.1325168609619 W\n",
      "[codecarbon INFO @ 21:35:00] Energy consumed for all CPUs : 0.000105 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 21:35:00] 0.000921 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:35:00] Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def run_feature_processing():\n",
    "    train_X, test_X, train_y, test_y = return_train_test_split()\n",
    "    print(\"###### Feature processing ######\")\n",
    "    fp = FeatureProcessing()\n",
    "    fp.fit(train_X,train_y)\n",
    "    x = fp.transform(train_X)\n",
    "    \n",
    "run_feature_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b206076adfde74b94edf3e7fcee64be8304c1723f9b5959762d795d94eb4b82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
