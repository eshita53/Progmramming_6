{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.delayed\n",
    "import yaml\n",
    "import numpy as np\n",
    "from scripts.data_processor_dask import DaskDataProcessor\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ### <span style=\"background-color: lightyellow;\"> Initial Data Preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dask.delayed\n",
    "def get_config(file_name):\n",
    "    with open(file_name, 'r', encoding=\"UTF-8\") as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    return config\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    config = get_config('../config.yaml').compute()\n",
    "    lung3 = config['lung3']\n",
    "    gene = config['gene']\n",
    "    lung3_df = dd.read_csv(lung3) \n",
    "    gene_df = dd.read_csv(gene, sep= '\\t', comment= \"!\").compute()\n",
    "    gene_df.set_index('ID_REF', inplace=True)\n",
    "    gene_df = gene_df.T\n",
    "    gene_df.reset_index(drop=True, inplace=True)\n",
    "    combined_df = lung3_df.merge(gene_df, left_index=True, right_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rmeshita/miniconda3/envs/dask_env/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 45823 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def setup_dask_client(n_workers=4, threads_per_worker=2, memory_limit='8GB'):\n",
    "    client = Client(n_workers=n_workers, \n",
    "                   threads_per_worker=threads_per_worker,\n",
    "                   memory_limit=memory_limit)\n",
    "    return client\n",
    "client = setup_dask_client(n_workers=4, \n",
    "                          threads_per_worker=2, \n",
    "                          memory_limit='16GB')\n",
    "\n",
    "def sub_classification(histology):\n",
    "    if \"Carcinoma\" in histology:\n",
    "        return 'Carcinoma'\n",
    "    elif \"Adenocarcinoma\" in histology:\n",
    "        return 'Adenocarcinoma'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rmeshita/miniconda3/envs/dask_env/lib/python3.10/site-packages/dask/dataframe/io/csv.py:508: UserWarning: Warning gzip compression does not support breaking apart files\n",
      "Please ensure that each individual file can fit in memory and\n",
      "use the keyword ``blocksize=None to remove this message``\n",
      "Setting ``blocksize=None``\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/rmeshita/miniconda3/envs/dask_env/lib/python3.10/site-packages/distributed/client.py:3383: UserWarning: Sending large graph of size 44.45 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/miniconda3/envs/dask_env/lib/python3.10/site-packages/distributed/client.py:3383: UserWarning: Sending large graph of size 44.45 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/homes/rmeshita/miniconda3/envs/dask_env/lib/python3.10/site-packages/distributed/client.py:3383: UserWarning: Sending large graph of size 44.45 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = retrieve_data()\n",
    "y = dataset['characteristics.tag.histology'].map(sub_classification, meta=('output_column', 'str'))\n",
    "dataset  = dataset.drop(columns='characteristics.tag.histology')\n",
    "print(\"dataset loaded\")\n",
    "\n",
    "data_processor = DaskDataProcessor(dataset)\n",
    "data_processor.remove_non_related_columns()\n",
    "data_processor.impute_not_available_values('characteristics.tag.grade')\n",
    "data_processor.drop_nan_columns(35)\n",
    "data_processor.cramerV(y, 0)\n",
    "covarrianced_columns = data_processor.covarianced_columns\n",
    "removed_catagorical_features = set(data_processor.find_cols_on_type('object')) - set(covarrianced_columns)\n",
    "data_processor.drop_columns(column_list = list(removed_catagorical_features))\n",
    "data_processor.selecting_high_variance_gene_expression(95)\n",
    "dataset = data_processor.dataframe\n",
    "dataset['classes'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: lightyellow;\">EDA Task</span>\n",
    "\n",
    "- Calculate summary statistics (e.g., mean, median, standard deviation) for clinical variables and gene expression data.\n",
    "- Identify the top 10 most variable genes across patients.\n",
    "- Group patients by clinical variables and compute the average expression of selected genes.\n",
    "- Visualize the distribution of the target variable (TumorSubtype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_statistics(df):\n",
    "    if not isinstance(df, dd.DataFrame):\n",
    "        df = dd.from_pandas(df, npartitions=4)  \n",
    "    numerical_cols = df.select_dtypes(include=[np.number])\n",
    "    describe_df = numerical_cols.describe().compute().T\n",
    "    median_values = numerical_cols.quantile(0.5).compute()\n",
    "    describe_df['median'] = median_values\n",
    "\n",
    "    stats_df = describe_df[['mean', 'median', 'std']]\n",
    "\n",
    "    return stats_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = calculate_statistics(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 10 most variable genes across patients.\n",
    "import re\n",
    "variances = {}\n",
    "gens = [col for col in dataset.columns if re.match(r'.*_at$',col)]\n",
    "for col in gens:\n",
    "    data = dataset[col].compute()\n",
    "    log_normalized = np.log1p(data)\n",
    "    variances[col] = log_normalized.var()\n",
    "    \n",
    "variances = list(sorted(variances.items(), key=lambda item: item[1], reverse=True))\n",
    "top_var_genes = [gene for gene, _ in variances[:10]]\n",
    "top_var_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Group patients by clinical variables and compute the average expression of selected genes\n",
    "dataset.compute().groupby(\"characteristics.tag.gender\")[top_var_genes].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Visualize the distribution of the target variable (TumorSubtype)\n",
    "dataset.compute()['classes'].value_counts().plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b206076adfde74b94edf3e7fcee64be8304c1723f9b5959762d795d94eb4b82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
