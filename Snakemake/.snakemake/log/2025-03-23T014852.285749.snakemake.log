Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 32
Rules claiming more threads will be scaled down.
Job stats:
job                      count    min threads    max threads
---------------------  -------  -------------  -------------
all                          1              1              1
analyzing_benchmarks         1              1              1
combine_results              1              1              1
data_preprocessing           1              1              1
data_retrieval               1              1              1
generate_report              1              1              1
model_evaluation             2              1              1
model_training               2              1              1
visualize_performance        1              1              1
total                       11              1              1

Select jobs to execute...

[Sun Mar 23 01:48:53 2025]
rule data_retrieval:
    input: data/Lung3.metadata.csv, data/GSE58661_series_matrix.txt.gz
    output: data/raw/train_X.csv, data/raw/test_X.csv, data/raw/train_y.csv, data/raw/test_y.csv
    jobid: 4
    reason: Missing output files: data/raw/test_X.csv, data/raw/train_y.csv, data/raw/train_X.csv, data/raw/test_y.csv
    resources: tmpdir=/tmp

[Sun Mar 23 01:48:53 2025]
Error in rule data_retrieval:
    jobid: 4
    input: data/Lung3.metadata.csv, data/GSE58661_series_matrix.txt.gz
    output: data/raw/train_X.csv, data/raw/test_X.csv, data/raw/train_y.csv, data/raw/test_y.csv

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-03-23T014852.285749.snakemake.log
