host: Mds-Laptop.local
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job              count
-------------  -------
data_retrival        1
total                1

Select jobs to execute...
Execute 1 jobs...

[Thu Mar 20 17:17:16 2025]
localrule data_retrival:
    input: data/Lung3.metadata.csv, data/GSE58661_series_matrix.txt.gz
    output: data/raw/train_X.csv, data/raw/test_X.csv, data/raw/train_y.csv, data/raw/test_y.csv
    jobid: 0
    reason: Code has changed since last execution; Params have changed since last execution: Union of exclusive params before and now across all output: before: <nothing exclusive> now: 'data_retrival','logs/workflow.log' 
    resources: tmpdir=/var/folders/vw/j0gj7skx0qdbp446rdwrjyz80000gn/T

RuleException:
CalledProcessError in file /Users/eshita-pc/Documents/Second_year/programming 6/Snakemake/main.smk, line 17:
Command 'set -euo pipefail;  /Users/eshita-pc/miniconda3/envs/paint/bin/python3.12 '/Users/eshita-pc/Documents/Second_year/programming 6/Snakemake/.snakemake/scripts/tmp0h5c1mqj.data_retrival.py'' returned non-zero exit status 1.
[Thu Mar 20 17:17:17 2025]
Error in rule data_retrival:
    jobid: 0
    input: data/Lung3.metadata.csv, data/GSE58661_series_matrix.txt.gz
    output: data/raw/train_X.csv, data/raw/test_X.csv, data/raw/train_y.csv, data/raw/test_y.csv

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-03-20T171716.372272.snakemake.log
WorkflowError:
At least one job did not complete successfully.
